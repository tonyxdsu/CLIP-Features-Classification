{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import clip_feature_extractor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import loguniform\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Extracting features from CIFAR100 dataset\n",
      "Loaded previously extracted features from disk.\n"
     ]
    }
   ],
   "source": [
    "X_train_CIFAR100, y_train_CIFAR100, X_test_CIFAR100, y_test_CIFAR100 = clip_feature_extractor.get_CIFAR100_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 80.020\n"
     ]
    }
   ],
   "source": [
    "# C = 0.316 provided by OpenAI\n",
    "\n",
    "log_reg_CIFAR100 = LogisticRegression(random_state=0, max_iter=1000, C=0.316, n_jobs=-1)\n",
    "log_reg_CIFAR100.fit(X_train_CIFAR100, y_train_CIFAR100)\n",
    "predictions_CIFAR100 = log_reg_CIFAR100.predict(X_test_CIFAR100)\n",
    "accuracy_CIFAR100 = np.mean((y_test_CIFAR100 == predictions_CIFAR100).astype(float)) * 100.\n",
    "print(f\"Accuracy = {accuracy_CIFAR100:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Loaded features from disk.\n"
     ]
    }
   ],
   "source": [
    "X_train_CIFAR10, y_train_CIFAR10, X_test_CIFAR10, y_test_CIFAR10 = clip_feature_extractor.get_CIFAR10_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n",
      "[CV 2/2] END logreg__C=0.0006306658668123951, logreg__l1_ratio=0.7777777777777777, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.898 total time=  14.7s\n",
      "[CV 1/2] END logreg__C=0.0006306658668123951, logreg__l1_ratio=0.7777777777777777, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.891 total time=  14.9s\n",
      "[CV 2/2] END logreg__C=0.00014610865886287216, logreg__l1_ratio=0.1111111111111111, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.919 total time=  20.7s\n",
      "[CV 1/2] END logreg__penalty=none, logreg__solver=sag;, score=nan total time=   0.5s\n",
      "[CV 2/2] END logreg__penalty=none, logreg__solver=sag;, score=nan total time=   0.5s\n",
      "[CV 1/2] END logreg__C=0.00014610865886287216, logreg__l1_ratio=0.1111111111111111, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.918 total time=  23.3s\n",
      "[CV 1/2] END logreg__C=0.00010144487859320233, logreg__penalty=l2, logreg__solver=saga;, score=0.935 total time=   8.2s\n",
      "[CV 2/2] END logreg__C=0.00010144487859320233, logreg__penalty=l2, logreg__solver=saga;, score=0.938 total time=   7.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END logreg__C=235.69148616733443, logreg__l1_ratio=0.7777777777777777, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.925 total time=28.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END logreg__C=235.69148616733443, logreg__l1_ratio=0.7777777777777777, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.928 total time=28.7min\n",
      "[CV 1/2] END logreg__C=0.00011390176182186649, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.935 total time=   2.1s\n",
      "[CV 2/2] END logreg__C=0.00011390176182186649, logreg__penalty=l2, logreg__solver=lbfgs;, score=0.939 total time=   2.1s\n",
      "[CV 2/2] END logreg__C=1.5783280762132288, logreg__penalty=l1, logreg__solver=liblinear;, score=0.943 total time= 2.4min\n",
      "[CV 1/2] END logreg__C=1.5783280762132288, logreg__penalty=l1, logreg__solver=liblinear;, score=0.942 total time= 2.5min\n",
      "[CV 2/2] END logreg__C=0.0002362246997776369, logreg__penalty=l2, logreg__solver=saga;, score=0.943 total time=   7.9s\n",
      "[CV 1/2] END logreg__penalty=none, logreg__solver=saga;, score=nan total time=   0.5s\n",
      "[CV 1/2] END logreg__C=0.0002362246997776369, logreg__penalty=l2, logreg__solver=saga;, score=0.939 total time=   9.5s\n",
      "[CV 2/2] END logreg__penalty=none, logreg__solver=saga;, score=nan total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END logreg__C=5.953896264004558, logreg__penalty=l1, logreg__solver=saga;, score=0.930 total time=31.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END logreg__C=6.4405075539937195, logreg__penalty=l1, logreg__solver=saga;, score=0.927 total time=31.7min\n",
      "[CV 1/2] END logreg__C=0.0005307029188745615, logreg__penalty=l2, logreg__solver=liblinear;, score=0.936 total time=  26.3s\n",
      "[CV 1/2] END logreg__penalty=none, logreg__solver=lbfgs;, score=nan total time=   0.5s\n",
      "[CV 2/2] END logreg__penalty=none, logreg__solver=lbfgs;, score=nan total time=   0.5s\n",
      "[CV 2/2] END logreg__C=0.0005307029188745615, logreg__penalty=l2, logreg__solver=liblinear;, score=0.939 total time=  27.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END logreg__C=5.953896264004558, logreg__penalty=l1, logreg__solver=saga;, score=0.927 total time=31.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END logreg__C=8.706669857047757, logreg__penalty=l1, logreg__solver=saga;, score=0.927 total time=31.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END logreg__C=8.706669857047757, logreg__penalty=l1, logreg__solver=saga;, score=0.930 total time=31.6min\n",
      "[CV 1/2] END logreg__penalty=none, logreg__solver=lbfgs;, score=nan total time=   0.6s\n",
      "[CV 2/2] END logreg__penalty=none, logreg__solver=lbfgs;, score=nan total time=   0.5s\n",
      "[CV 1/2] END logreg__penalty=none, logreg__solver=sag;, score=nan total time=   0.5s\n",
      "[CV 2/2] END logreg__penalty=none, logreg__solver=sag;, score=nan total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END logreg__C=6.4405075539937195, logreg__penalty=l1, logreg__solver=saga;, score=0.930 total time=32.6min\n",
      "[CV 1/2] END logreg__C=0.12115239957904832, logreg__penalty=l2, logreg__solver=liblinear;, score=0.945 total time= 1.1min\n",
      "[CV 2/2] END logreg__C=0.12115239957904832, logreg__penalty=l2, logreg__solver=liblinear;, score=0.950 total time= 1.1min\n",
      "[CV 1/2] END logreg__C=0.0070331617412763316, logreg__penalty=l1, logreg__solver=saga;, score=0.932 total time=  37.2s\n",
      "[CV 2/2] END logreg__C=0.0070331617412763316, logreg__penalty=l1, logreg__solver=saga;, score=0.934 total time=  34.3s\n",
      "[CV 1/2] END logreg__C=0.11473500268396371, logreg__l1_ratio=0.3333333333333333, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.945 total time=11.3min\n",
      "[CV 1/2] END logreg__C=0.0024373462416671784, logreg__l1_ratio=0.0, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.947 total time=  38.6s\n",
      "[CV 2/2] END logreg__C=0.0024373462416671784, logreg__l1_ratio=0.0, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.950 total time=  46.5s\n",
      "[CV 1/2] END logreg__penalty=none, logreg__solver=sag;, score=nan total time=   0.6s\n",
      "[CV 2/2] END logreg__penalty=none, logreg__solver=sag;, score=nan total time=   0.6s\n",
      "[CV 1/2] END logreg__penalty=none, logreg__solver=sag;, score=nan total time=   0.6s\n",
      "[CV 2/2] END logreg__penalty=none, logreg__solver=sag;, score=nan total time=   0.6s\n",
      "[CV 2/2] END logreg__C=0.11473500268396371, logreg__l1_ratio=0.3333333333333333, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.947 total time=17.3min\n",
      "[CV 1/2] END logreg__C=0.4017852745189947, logreg__penalty=l1, logreg__solver=saga;, score=0.942 total time=24.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END logreg__C=0.4017852745189947, logreg__penalty=l1, logreg__solver=saga;, score=0.945 total time=26.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END logreg__C=757.7453045410584, logreg__l1_ratio=0.6666666666666666, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.925 total time=29.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END logreg__C=757.7453045410584, logreg__l1_ratio=0.6666666666666666, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.928 total time=30.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END logreg__C=29.24880658395848, logreg__l1_ratio=0.7777777777777777, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.928 total time=30.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END logreg__C=29.24880658395848, logreg__l1_ratio=0.7777777777777777, logreg__penalty=elasticnet, logreg__solver=saga;, score=0.926 total time=30.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "14 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/tonyxdsu/.local/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.92658 0.92868 0.89454 0.9285  0.91852     nan 0.93648 0.92814 0.937\n",
      " 0.9425  0.94116     nan 0.93742 0.94604     nan 0.92632 0.94364     nan\n",
      "     nan 0.94758 0.93274 0.92692 0.9486      nan     nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'logreg__C': np.float64(0.0024373462416671784), 'logreg__l1_ratio': np.float64(0.0), 'logreg__penalty': 'elasticnet', 'logreg__solver': 'saga'}\n",
      "Best cross-validation score:  0.9486\n",
      "Test set accuracy:  0.9492\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with data scaling and logistic regression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define the parameter distributions with valid solver-penalty combinations\n",
    "param_distributions = [\n",
    "    {\n",
    "        'logreg__penalty': ['l1'],\n",
    "        'logreg__C': loguniform(1e-4, 1e4),\n",
    "        'logreg__solver': ['liblinear', 'saga'],\n",
    "    },\n",
    "    {\n",
    "        'logreg__penalty': ['l2'],\n",
    "        'logreg__C': loguniform(1e-4, 1e4),\n",
    "        'logreg__solver': ['lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    },\n",
    "    {\n",
    "        'logreg__penalty': ['elasticnet'],\n",
    "        'logreg__C': loguniform(1e-4, 1e4),\n",
    "        'logreg__solver': ['saga'],\n",
    "        'logreg__l1_ratio': np.linspace(0, 1, 10),\n",
    "    },\n",
    "    {\n",
    "        'logreg__penalty': ['none'],\n",
    "        'logreg__solver': ['lbfgs', 'sag', 'saga'],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=25,\n",
    "    cv=2,\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "random_search.fit(X_train_CIFAR10, y_train_CIFAR10)\n",
    "\n",
    "# Output the best parameters and score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation score: \", random_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "test_score = best_model.score(X_test_CIFAR10, y_test_CIFAR10)\n",
    "print(\"Test set accuracy: \", test_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
