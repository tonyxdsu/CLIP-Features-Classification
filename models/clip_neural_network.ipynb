{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following cell if using Google Colab\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd /content/drive/MyDrive/cs340/project/models\n",
    "\n",
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import clip_feature_extractor\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import random\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(device)\n",
    "\n",
    "import cupy as cp\n",
    "import cudf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Extracting features from CIFAR100 dataset\n",
      "Loaded previously extracted features from disk.\n"
     ]
    }
   ],
   "source": [
    "X_train_CIFAR100_np, y_train_CIFAR100_np, X_test_CIFAR100_np, y_test_CIFAR100_np = clip_feature_extractor.get_CIFAR100_features();\n",
    "\n",
    "# TODO this doesn't help? Or redundant with batchnorm? Or is it still needed with batchnorm?\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train = torch.tensor(X_train_CIFAR100_np, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train_CIFAR100_np, dtype=torch.long)\n",
    "X_test  = torch.tensor(X_test_CIFAR100_np, dtype=torch.float32)\n",
    "y_test  = torch.tensor(y_test_CIFAR100_np, dtype=torch.long)\n",
    "\n",
    "full_train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fcnet_CIFAR100(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, dropout_p1=0.2, dropout_p2=0.2):\n",
    "        super(fcnet_CIFAR100, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=dropout_p1)  \n",
    "\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(p=dropout_p2) \n",
    "\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(input_size, \n",
    "                       num_classes, \n",
    "                       train_loader, \n",
    "                       val_loader, \n",
    "                       test_loader,\n",
    "                       device='cuda', \n",
    "                       dropout_p1=0.2, \n",
    "                       dropout_p2=0.2, \n",
    "                       lr=0.001, \n",
    "                       weight_decay=0.001,\n",
    "                       num_epochs=50,\n",
    "                       patience=5,\n",
    "                       verbose=False):\n",
    "    \"\"\"\n",
    "    Trains the fcnet_CIFAR100 model and evaluates its performance on validation loss.\n",
    "\n",
    "    Parameters:\n",
    "    - input_size (int): Dimensionality of input features.\n",
    "    - num_classes (int): Number of target classes.\n",
    "    - train_loader, val_loader, test_loader: DataLoaders for training, validation, and testing.\n",
    "    - device (str): 'cuda' or 'cpu'.\n",
    "    - dropout_p1 (float): Dropout probability after first layer.\n",
    "    - dropout_p2 (float): Dropout probability after second layer.\n",
    "    - lr (float): Learning rate for the optimizer.\n",
    "    - weight_decay (float): Weight decay (L2 regularization) factor.\n",
    "    - num_epochs (int): Maximum number of training epochs.\n",
    "    - patience (int): Number of epochs to wait for improvement before stopping.\n",
    "    - verbose (bool): If True, prints progress at each epoch.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Contains the trained model and performance metrics.\n",
    "    \"\"\"\n",
    "    model = fcnet_CIFAR100(input_size=input_size, num_classes=num_classes,\n",
    "                           dropout_p1=dropout_p1, dropout_p2=dropout_p2)\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # training\n",
    "    time_start = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = correct / total\n",
    "\n",
    "        # validation \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for val_batch_X, val_batch_y in val_loader:\n",
    "                val_batch_X, val_batch_y = val_batch_X.to(device), val_batch_y.to(device)\n",
    "\n",
    "                val_outputs = model(val_batch_X)\n",
    "                v_loss = criterion(val_outputs, val_batch_y)\n",
    "\n",
    "                val_loss += v_loss.item()\n",
    "\n",
    "                _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                val_total += val_batch_y.size(0)\n",
    "                val_correct += (val_predicted == val_batch_y).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        # early stopping\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "        \n",
    "        time_end = time.time()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy*100:.2f}%, \"\n",
    "                f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy*100:.2f}%\")\n",
    "            if (epoch == 0):\n",
    "                print(f\"Estimate time per epoch: {time_end - time_start:.2f} seconds\")\n",
    "\n",
    "    # Load the best model state\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # test\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for test_batch_X, test_batch_y in test_loader:\n",
    "            test_batch_X, test_batch_y = test_batch_X.to(device), test_batch_y.to(device)\n",
    "\n",
    "            test_outputs = model(test_batch_X)\n",
    "            t_loss = criterion(test_outputs, test_batch_y)\n",
    "\n",
    "            test_loss += t_loss.item()\n",
    "\n",
    "            _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "            test_total += test_batch_y.size(0)\n",
    "            test_correct += (test_predicted == test_batch_y).sum().item()\n",
    "\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = test_correct / test_total\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'val_loss': best_val_loss,\n",
    "        'test_accuracy': test_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Trial 1/20: {'dropout_p1': 0.6732170919020518, 'dropout_p2': 0.5823287398805788, 'lr': 0.0006742635192431502, 'weight_decay': 0.004090461939684706}\n",
      "Epoch 1/50, Train Loss: 2.4489, Train Acc: 52.32%, Val Loss: 1.0404, Val Acc: 72.36%\n",
      "Epoch 2/50, Train Loss: 1.3255, Train Acc: 64.66%, Val Loss: 0.9723, Val Acc: 73.80%\n",
      "Estimate time per epoch: 16.96 seconds\n",
      "Epoch 3/50, Train Loss: 1.2897, Train Acc: 65.33%, Val Loss: 0.9599, Val Acc: 74.42%\n",
      "Epoch 4/50, Train Loss: 1.2688, Train Acc: 65.82%, Val Loss: 0.9388, Val Acc: 74.04%\n",
      "Epoch 5/50, Train Loss: 1.2640, Train Acc: 66.00%, Val Loss: 0.9272, Val Acc: 74.65%\n",
      "Epoch 6/50, Train Loss: 1.2562, Train Acc: 66.38%, Val Loss: 0.9277, Val Acc: 74.28%\n",
      "Epoch 7/50, Train Loss: 1.2595, Train Acc: 66.16%, Val Loss: 0.9363, Val Acc: 74.41%\n",
      "Epoch 8/50, Train Loss: 1.2487, Train Acc: 66.29%, Val Loss: 0.9248, Val Acc: 74.43%\n",
      "Epoch 9/50, Train Loss: 1.2626, Train Acc: 66.38%, Val Loss: 0.9280, Val Acc: 74.30%\n",
      "Epoch 10/50, Train Loss: 1.2521, Train Acc: 66.54%, Val Loss: 0.9355, Val Acc: 74.37%\n",
      "Epoch 11/50, Train Loss: 1.2514, Train Acc: 66.30%, Val Loss: 0.9323, Val Acc: 73.80%\n",
      "Epoch 12/50, Train Loss: 1.2557, Train Acc: 66.46%, Val Loss: 0.9454, Val Acc: 74.26%\n",
      "Early stopping triggered at epoch 13\n",
      "New best model found with Val Loss: 0.9248 and Test Accuracy: 74.48%\n",
      "\n",
      "== Trial 2/20: {'dropout_p1': 0.5796455861122985, 'dropout_p2': 0.5302244760036776, 'lr': 0.0002818460340897655, 'weight_decay': 0.009982252101834265}\n",
      "Epoch 1/50, Train Loss: 3.4397, Train Acc: 50.57%, Val Loss: 1.2470, Val Acc: 72.66%\n",
      "Epoch 2/50, Train Loss: 1.3537, Train Acc: 68.73%, Val Loss: 1.0617, Val Acc: 75.17%\n",
      "Estimate time per epoch: 16.03 seconds\n",
      "Epoch 3/50, Train Loss: 1.2750, Train Acc: 69.95%, Val Loss: 1.0484, Val Acc: 75.45%\n",
      "Epoch 4/50, Train Loss: 1.2490, Train Acc: 70.88%, Val Loss: 1.0272, Val Acc: 75.78%\n",
      "Epoch 5/50, Train Loss: 1.2328, Train Acc: 70.71%, Val Loss: 1.0212, Val Acc: 75.67%\n",
      "Epoch 6/50, Train Loss: 1.2232, Train Acc: 71.18%, Val Loss: 0.9885, Val Acc: 75.84%\n",
      "Epoch 7/50, Train Loss: 1.2151, Train Acc: 71.25%, Val Loss: 0.9993, Val Acc: 75.89%\n",
      "Epoch 8/50, Train Loss: 1.2061, Train Acc: 71.61%, Val Loss: 0.9890, Val Acc: 75.83%\n",
      "Epoch 9/50, Train Loss: 1.2114, Train Acc: 71.58%, Val Loss: 0.9778, Val Acc: 76.02%\n",
      "Epoch 10/50, Train Loss: 1.1989, Train Acc: 71.80%, Val Loss: 0.9788, Val Acc: 75.59%\n",
      "Epoch 11/50, Train Loss: 1.2017, Train Acc: 71.49%, Val Loss: 0.9824, Val Acc: 75.90%\n",
      "Epoch 12/50, Train Loss: 1.1979, Train Acc: 71.75%, Val Loss: 0.9781, Val Acc: 75.65%\n",
      "Epoch 13/50, Train Loss: 1.1986, Train Acc: 71.83%, Val Loss: 0.9664, Val Acc: 76.16%\n",
      "Epoch 14/50, Train Loss: 1.2017, Train Acc: 71.78%, Val Loss: 0.9717, Val Acc: 76.16%\n",
      "Epoch 15/50, Train Loss: 1.2025, Train Acc: 71.81%, Val Loss: 0.9667, Val Acc: 76.81%\n",
      "Epoch 16/50, Train Loss: 1.2046, Train Acc: 71.56%, Val Loss: 0.9780, Val Acc: 75.59%\n",
      "Epoch 17/50, Train Loss: 1.2008, Train Acc: 71.51%, Val Loss: 0.9795, Val Acc: 76.01%\n",
      "Early stopping triggered at epoch 18\n",
      "No improvement. Current Best Val Loss: 0.9248, Test Accuracy: 74.48%\n",
      "\n",
      "== Trial 3/20: {'dropout_p1': 0.6621772753622809, 'dropout_p2': 0.4686465969909497, 'lr': 0.000924829113168127, 'weight_decay': 0.0038742170594138177}\n",
      "Epoch 1/50, Train Loss: 2.0802, Train Acc: 55.87%, Val Loss: 1.0505, Val Acc: 71.26%\n",
      "Epoch 2/50, Train Loss: 1.3145, Train Acc: 64.52%, Val Loss: 0.9923, Val Acc: 72.85%\n",
      "Estimate time per epoch: 17.69 seconds\n",
      "Epoch 3/50, Train Loss: 1.2834, Train Acc: 65.33%, Val Loss: 0.9800, Val Acc: 73.07%\n",
      "Epoch 4/50, Train Loss: 1.2876, Train Acc: 64.94%, Val Loss: 0.9995, Val Acc: 72.53%\n",
      "Epoch 5/50, Train Loss: 1.2827, Train Acc: 65.12%, Val Loss: 0.9795, Val Acc: 72.47%\n",
      "Epoch 6/50, Train Loss: 1.2863, Train Acc: 64.85%, Val Loss: 0.9735, Val Acc: 73.11%\n",
      "Epoch 7/50, Train Loss: 1.2854, Train Acc: 65.21%, Val Loss: 0.9879, Val Acc: 72.67%\n",
      "Epoch 8/50, Train Loss: 1.2830, Train Acc: 65.25%, Val Loss: 0.9894, Val Acc: 72.50%\n",
      "Epoch 9/50, Train Loss: 1.2788, Train Acc: 65.24%, Val Loss: 0.9819, Val Acc: 72.79%\n",
      "Epoch 10/50, Train Loss: 1.2803, Train Acc: 65.37%, Val Loss: 0.9851, Val Acc: 72.66%\n",
      "Early stopping triggered at epoch 11\n",
      "No improvement. Current Best Val Loss: 0.9248, Test Accuracy: 74.48%\n",
      "\n",
      "== Trial 4/20: {'dropout_p1': 0.6588663808220432, 'dropout_p2': 0.4000303381667901, 'lr': 0.00032142070670549945, 'weight_decay': 0.0022320727535635196}\n",
      "Epoch 1/50, Train Loss: 2.7949, Train Acc: 53.73%, Val Loss: 0.9868, Val Acc: 73.96%\n",
      "Epoch 2/50, Train Loss: 1.1049, Train Acc: 69.93%, Val Loss: 0.8564, Val Acc: 75.90%\n",
      "Estimate time per epoch: 17.72 seconds\n",
      "Epoch 3/50, Train Loss: 1.0123, Train Acc: 72.16%, Val Loss: 0.8286, Val Acc: 76.32%\n",
      "Epoch 4/50, Train Loss: 0.9752, Train Acc: 72.86%, Val Loss: 0.8042, Val Acc: 76.92%\n",
      "Epoch 5/50, Train Loss: 0.9497, Train Acc: 73.56%, Val Loss: 0.7874, Val Acc: 77.28%\n",
      "Epoch 6/50, Train Loss: 0.9246, Train Acc: 74.11%, Val Loss: 0.7857, Val Acc: 77.17%\n",
      "Epoch 7/50, Train Loss: 0.9151, Train Acc: 74.31%, Val Loss: 0.7856, Val Acc: 77.14%\n",
      "Epoch 8/50, Train Loss: 0.9081, Train Acc: 74.41%, Val Loss: 0.7694, Val Acc: 77.66%\n",
      "Epoch 9/50, Train Loss: 0.8995, Train Acc: 74.78%, Val Loss: 0.7699, Val Acc: 77.64%\n",
      "Epoch 10/50, Train Loss: 0.8920, Train Acc: 75.16%, Val Loss: 0.7741, Val Acc: 77.50%\n",
      "Epoch 11/50, Train Loss: 0.8905, Train Acc: 74.87%, Val Loss: 0.7674, Val Acc: 77.52%\n",
      "Epoch 12/50, Train Loss: 0.8841, Train Acc: 75.42%, Val Loss: 0.7627, Val Acc: 78.01%\n",
      "Epoch 13/50, Train Loss: 0.8787, Train Acc: 75.33%, Val Loss: 0.7643, Val Acc: 77.65%\n",
      "Epoch 14/50, Train Loss: 0.8789, Train Acc: 75.33%, Val Loss: 0.7573, Val Acc: 78.35%\n",
      "Epoch 15/50, Train Loss: 0.8691, Train Acc: 75.65%, Val Loss: 0.7647, Val Acc: 77.72%\n",
      "Epoch 16/50, Train Loss: 0.8695, Train Acc: 75.42%, Val Loss: 0.7558, Val Acc: 77.90%\n",
      "Epoch 17/50, Train Loss: 0.8714, Train Acc: 75.41%, Val Loss: 0.7591, Val Acc: 78.00%\n",
      "Epoch 18/50, Train Loss: 0.8630, Train Acc: 75.70%, Val Loss: 0.7616, Val Acc: 77.79%\n",
      "Epoch 19/50, Train Loss: 0.8665, Train Acc: 75.50%, Val Loss: 0.7598, Val Acc: 77.64%\n",
      "Epoch 20/50, Train Loss: 0.8572, Train Acc: 75.84%, Val Loss: 0.7570, Val Acc: 77.93%\n",
      "Epoch 21/50, Train Loss: 0.8616, Train Acc: 75.59%, Val Loss: 0.7538, Val Acc: 78.08%\n",
      "Epoch 22/50, Train Loss: 0.8590, Train Acc: 75.56%, Val Loss: 0.7522, Val Acc: 78.14%\n",
      "Epoch 23/50, Train Loss: 0.8593, Train Acc: 75.73%, Val Loss: 0.7635, Val Acc: 77.75%\n",
      "Epoch 24/50, Train Loss: 0.8562, Train Acc: 75.92%, Val Loss: 0.7530, Val Acc: 78.22%\n",
      "Epoch 25/50, Train Loss: 0.8541, Train Acc: 75.81%, Val Loss: 0.7534, Val Acc: 77.99%\n",
      "Epoch 26/50, Train Loss: 0.8524, Train Acc: 75.98%, Val Loss: 0.7496, Val Acc: 78.51%\n",
      "Epoch 27/50, Train Loss: 0.8521, Train Acc: 76.01%, Val Loss: 0.7623, Val Acc: 77.81%\n",
      "Epoch 28/50, Train Loss: 0.8528, Train Acc: 76.05%, Val Loss: 0.7581, Val Acc: 78.11%\n",
      "Epoch 29/50, Train Loss: 0.8627, Train Acc: 75.61%, Val Loss: 0.7527, Val Acc: 78.28%\n",
      "Epoch 30/50, Train Loss: 0.8542, Train Acc: 76.19%, Val Loss: 0.7519, Val Acc: 77.89%\n",
      "Early stopping triggered at epoch 31\n",
      "New best model found with Val Loss: 0.7496 and Test Accuracy: 78.11%\n",
      "\n",
      "== Trial 5/20: {'dropout_p1': 0.5235093475537135, 'dropout_p2': 0.41768418774618976, 'lr': 0.0007722083247834438, 'weight_decay': 0.005391632044125157}\n",
      "Epoch 1/50, Train Loss: 2.0098, Train Acc: 59.72%, Val Loss: 1.0329, Val Acc: 72.46%\n",
      "Epoch 2/50, Train Loss: 1.2227, Train Acc: 67.76%, Val Loss: 1.0003, Val Acc: 73.11%\n",
      "Estimate time per epoch: 17.07 seconds\n",
      "Epoch 3/50, Train Loss: 1.2095, Train Acc: 67.89%, Val Loss: 1.0099, Val Acc: 72.34%\n",
      "Epoch 4/50, Train Loss: 1.2055, Train Acc: 68.01%, Val Loss: 0.9826, Val Acc: 72.52%\n",
      "Epoch 5/50, Train Loss: 1.2019, Train Acc: 68.34%, Val Loss: 0.9985, Val Acc: 73.16%\n",
      "Epoch 6/50, Train Loss: 1.1978, Train Acc: 68.34%, Val Loss: 1.0132, Val Acc: 72.52%\n",
      "Epoch 7/50, Train Loss: 1.2067, Train Acc: 68.04%, Val Loss: 0.9899, Val Acc: 73.37%\n",
      "Epoch 8/50, Train Loss: 1.2023, Train Acc: 68.27%, Val Loss: 0.9868, Val Acc: 73.12%\n",
      "Early stopping triggered at epoch 9\n",
      "No improvement. Current Best Val Loss: 0.7496, Test Accuracy: 78.11%\n",
      "\n",
      "== Trial 6/20: {'dropout_p1': 0.5659581871730067, 'dropout_p2': 0.5462022758707227, 'lr': 0.00010788437726010828, 'weight_decay': 0.001788680846335477}\n",
      "Epoch 1/50, Train Loss: 5.3185, Train Acc: 37.33%, Val Loss: 2.0825, Val Acc: 67.40%\n",
      "Epoch 2/50, Train Loss: 1.6173, Train Acc: 63.35%, Val Loss: 1.0940, Val Acc: 74.00%\n",
      "Estimate time per epoch: 15.66 seconds\n",
      "Epoch 3/50, Train Loss: 1.1704, Train Acc: 69.87%, Val Loss: 0.8894, Val Acc: 76.20%\n",
      "Epoch 4/50, Train Loss: 1.0292, Train Acc: 72.63%, Val Loss: 0.8234, Val Acc: 77.13%\n",
      "Epoch 5/50, Train Loss: 0.9490, Train Acc: 73.80%, Val Loss: 0.7827, Val Acc: 77.57%\n",
      "Epoch 6/50, Train Loss: 0.9043, Train Acc: 75.06%, Val Loss: 0.7653, Val Acc: 78.08%\n",
      "Epoch 7/50, Train Loss: 0.8704, Train Acc: 75.91%, Val Loss: 0.7542, Val Acc: 78.23%\n",
      "Epoch 8/50, Train Loss: 0.8380, Train Acc: 76.55%, Val Loss: 0.7385, Val Acc: 78.73%\n",
      "Epoch 9/50, Train Loss: 0.8119, Train Acc: 77.45%, Val Loss: 0.7319, Val Acc: 78.59%\n",
      "Epoch 10/50, Train Loss: 0.7909, Train Acc: 77.98%, Val Loss: 0.7236, Val Acc: 78.68%\n",
      "Epoch 11/50, Train Loss: 0.7726, Train Acc: 78.33%, Val Loss: 0.7149, Val Acc: 79.15%\n",
      "Epoch 12/50, Train Loss: 0.7715, Train Acc: 78.37%, Val Loss: 0.7100, Val Acc: 79.37%\n",
      "Epoch 13/50, Train Loss: 0.7512, Train Acc: 78.85%, Val Loss: 0.7083, Val Acc: 79.11%\n",
      "Epoch 14/50, Train Loss: 0.7311, Train Acc: 79.59%, Val Loss: 0.7075, Val Acc: 79.33%\n",
      "Epoch 15/50, Train Loss: 0.7253, Train Acc: 79.38%, Val Loss: 0.7124, Val Acc: 79.27%\n",
      "Epoch 16/50, Train Loss: 0.7187, Train Acc: 79.44%, Val Loss: 0.7009, Val Acc: 79.69%\n",
      "Epoch 17/50, Train Loss: 0.7018, Train Acc: 80.19%, Val Loss: 0.7014, Val Acc: 79.20%\n",
      "Epoch 18/50, Train Loss: 0.6956, Train Acc: 80.44%, Val Loss: 0.6955, Val Acc: 79.72%\n",
      "Epoch 19/50, Train Loss: 0.6829, Train Acc: 80.72%, Val Loss: 0.6935, Val Acc: 79.94%\n",
      "Epoch 20/50, Train Loss: 0.6753, Train Acc: 80.88%, Val Loss: 0.6900, Val Acc: 79.76%\n",
      "Epoch 21/50, Train Loss: 0.6757, Train Acc: 80.85%, Val Loss: 0.6930, Val Acc: 79.91%\n",
      "Epoch 22/50, Train Loss: 0.6638, Train Acc: 81.44%, Val Loss: 0.6887, Val Acc: 80.01%\n",
      "Epoch 23/50, Train Loss: 0.6560, Train Acc: 81.36%, Val Loss: 0.6867, Val Acc: 79.70%\n",
      "Epoch 24/50, Train Loss: 0.6574, Train Acc: 81.47%, Val Loss: 0.6848, Val Acc: 79.94%\n",
      "Epoch 25/50, Train Loss: 0.6428, Train Acc: 81.84%, Val Loss: 0.6885, Val Acc: 79.70%\n",
      "Epoch 26/50, Train Loss: 0.6391, Train Acc: 81.98%, Val Loss: 0.6929, Val Acc: 79.61%\n",
      "Epoch 27/50, Train Loss: 0.6297, Train Acc: 82.29%, Val Loss: 0.6863, Val Acc: 79.77%\n",
      "Epoch 28/50, Train Loss: 0.6271, Train Acc: 82.25%, Val Loss: 0.6873, Val Acc: 79.83%\n",
      "Epoch 29/50, Train Loss: 0.6213, Train Acc: 82.34%, Val Loss: 0.6819, Val Acc: 79.95%\n",
      "Epoch 30/50, Train Loss: 0.6155, Train Acc: 82.60%, Val Loss: 0.6841, Val Acc: 79.97%\n",
      "Epoch 31/50, Train Loss: 0.6191, Train Acc: 82.37%, Val Loss: 0.6816, Val Acc: 80.22%\n",
      "Epoch 32/50, Train Loss: 0.6047, Train Acc: 82.80%, Val Loss: 0.6853, Val Acc: 79.75%\n",
      "Epoch 33/50, Train Loss: 0.5964, Train Acc: 83.14%, Val Loss: 0.6788, Val Acc: 80.18%\n",
      "Epoch 34/50, Train Loss: 0.5931, Train Acc: 83.07%, Val Loss: 0.6827, Val Acc: 80.01%\n",
      "Epoch 35/50, Train Loss: 0.5861, Train Acc: 83.16%, Val Loss: 0.6790, Val Acc: 80.00%\n",
      "Epoch 36/50, Train Loss: 0.5862, Train Acc: 83.47%, Val Loss: 0.6812, Val Acc: 80.01%\n",
      "Epoch 37/50, Train Loss: 0.5845, Train Acc: 83.19%, Val Loss: 0.6835, Val Acc: 80.00%\n",
      "Early stopping triggered at epoch 38\n",
      "New best model found with Val Loss: 0.6788 and Test Accuracy: 80.12%\n",
      "\n",
      "== Trial 7/20: {'dropout_p1': 0.6278542972169283, 'dropout_p2': 0.48849445096785676, 'lr': 0.000785316467263667, 'weight_decay': 0.008130460199557293}\n",
      "Epoch 1/50, Train Loss: 2.2998, Train Acc: 55.21%, Val Loss: 1.2081, Val Acc: 70.30%\n",
      "Epoch 2/50, Train Loss: 1.4424, Train Acc: 63.49%, Val Loss: 1.1312, Val Acc: 71.37%\n",
      "Estimate time per epoch: 16.58 seconds\n",
      "Epoch 3/50, Train Loss: 1.4225, Train Acc: 63.85%, Val Loss: 1.1417, Val Acc: 70.79%\n",
      "Epoch 4/50, Train Loss: 1.4184, Train Acc: 63.96%, Val Loss: 1.1401, Val Acc: 70.17%\n",
      "Epoch 5/50, Train Loss: 1.4201, Train Acc: 63.71%, Val Loss: 1.1374, Val Acc: 70.84%\n",
      "Epoch 6/50, Train Loss: 1.4178, Train Acc: 64.12%, Val Loss: 1.1263, Val Acc: 71.31%\n",
      "Epoch 7/50, Train Loss: 1.4159, Train Acc: 63.95%, Val Loss: 1.1042, Val Acc: 71.76%\n",
      "Epoch 8/50, Train Loss: 1.4176, Train Acc: 63.87%, Val Loss: 1.1368, Val Acc: 71.86%\n",
      "Epoch 9/50, Train Loss: 1.4146, Train Acc: 63.91%, Val Loss: 1.1309, Val Acc: 71.67%\n",
      "Epoch 10/50, Train Loss: 1.4149, Train Acc: 64.12%, Val Loss: 1.1167, Val Acc: 71.40%\n",
      "Epoch 11/50, Train Loss: 1.4177, Train Acc: 63.62%, Val Loss: 1.1314, Val Acc: 71.51%\n",
      "Early stopping triggered at epoch 12\n",
      "No improvement. Current Best Val Loss: 0.6788, Test Accuracy: 80.12%\n",
      "\n",
      "== Trial 8/20: {'dropout_p1': 0.5253554572783057, 'dropout_p2': 0.5851059705301832, 'lr': 0.00011730797198485153, 'weight_decay': 0.0013219888016557314}\n",
      "Epoch 1/50, Train Loss: 4.9690, Train Acc: 39.20%, Val Loss: 1.9213, Val Acc: 69.84%\n",
      "Epoch 2/50, Train Loss: 1.5430, Train Acc: 64.30%, Val Loss: 1.0294, Val Acc: 74.63%\n",
      "Estimate time per epoch: 23.49 seconds\n",
      "Epoch 3/50, Train Loss: 1.1441, Train Acc: 69.97%, Val Loss: 0.8657, Val Acc: 76.37%\n",
      "Epoch 4/50, Train Loss: 1.0073, Train Acc: 72.50%, Val Loss: 0.7944, Val Acc: 77.48%\n",
      "Epoch 5/50, Train Loss: 0.9369, Train Acc: 74.14%, Val Loss: 0.7683, Val Acc: 77.75%\n",
      "Epoch 6/50, Train Loss: 0.8845, Train Acc: 75.26%, Val Loss: 0.7433, Val Acc: 78.47%\n",
      "Epoch 7/50, Train Loss: 0.8441, Train Acc: 76.35%, Val Loss: 0.7345, Val Acc: 78.34%\n",
      "Epoch 8/50, Train Loss: 0.8168, Train Acc: 76.90%, Val Loss: 0.7265, Val Acc: 79.00%\n",
      "Epoch 9/50, Train Loss: 0.7934, Train Acc: 77.44%, Val Loss: 0.7174, Val Acc: 79.12%\n",
      "Epoch 10/50, Train Loss: 0.7737, Train Acc: 78.08%, Val Loss: 0.7162, Val Acc: 78.95%\n",
      "Epoch 11/50, Train Loss: 0.7549, Train Acc: 78.56%, Val Loss: 0.7087, Val Acc: 79.06%\n",
      "Epoch 12/50, Train Loss: 0.7392, Train Acc: 78.72%, Val Loss: 0.7009, Val Acc: 79.42%\n",
      "Epoch 13/50, Train Loss: 0.7214, Train Acc: 79.31%, Val Loss: 0.7034, Val Acc: 79.09%\n",
      "Epoch 14/50, Train Loss: 0.7131, Train Acc: 79.48%, Val Loss: 0.6908, Val Acc: 79.54%\n",
      "Epoch 15/50, Train Loss: 0.7010, Train Acc: 79.77%, Val Loss: 0.6929, Val Acc: 79.76%\n",
      "Epoch 16/50, Train Loss: 0.6871, Train Acc: 80.22%, Val Loss: 0.6934, Val Acc: 79.38%\n",
      "Epoch 17/50, Train Loss: 0.6815, Train Acc: 80.45%, Val Loss: 0.6900, Val Acc: 79.61%\n",
      "Epoch 18/50, Train Loss: 0.6634, Train Acc: 81.03%, Val Loss: 0.6827, Val Acc: 80.11%\n",
      "Epoch 19/50, Train Loss: 0.6574, Train Acc: 80.78%, Val Loss: 0.6787, Val Acc: 80.23%\n",
      "Epoch 20/50, Train Loss: 0.6469, Train Acc: 81.65%, Val Loss: 0.6805, Val Acc: 79.85%\n",
      "Epoch 21/50, Train Loss: 0.6431, Train Acc: 81.33%, Val Loss: 0.6828, Val Acc: 79.94%\n",
      "Epoch 22/50, Train Loss: 0.6332, Train Acc: 81.71%, Val Loss: 0.6798, Val Acc: 79.97%\n",
      "Epoch 23/50, Train Loss: 0.6314, Train Acc: 81.72%, Val Loss: 0.6814, Val Acc: 79.95%\n",
      "Epoch 24/50, Train Loss: 0.6230, Train Acc: 82.14%, Val Loss: 0.6754, Val Acc: 80.25%\n",
      "Epoch 25/50, Train Loss: 0.6137, Train Acc: 82.21%, Val Loss: 0.6755, Val Acc: 80.04%\n",
      "Epoch 26/50, Train Loss: 0.6046, Train Acc: 82.54%, Val Loss: 0.6763, Val Acc: 80.24%\n",
      "Epoch 27/50, Train Loss: 0.5981, Train Acc: 82.64%, Val Loss: 0.6823, Val Acc: 79.99%\n",
      "Epoch 28/50, Train Loss: 0.5968, Train Acc: 82.80%, Val Loss: 0.6769, Val Acc: 80.23%\n",
      "Epoch 29/50, Train Loss: 0.5923, Train Acc: 82.64%, Val Loss: 0.6683, Val Acc: 80.13%\n",
      "Epoch 30/50, Train Loss: 0.5818, Train Acc: 83.30%, Val Loss: 0.6729, Val Acc: 80.02%\n",
      "Epoch 31/50, Train Loss: 0.5678, Train Acc: 83.52%, Val Loss: 0.6839, Val Acc: 80.02%\n",
      "Epoch 32/50, Train Loss: 0.5659, Train Acc: 83.55%, Val Loss: 0.6748, Val Acc: 79.96%\n",
      "Epoch 33/50, Train Loss: 0.5604, Train Acc: 83.63%, Val Loss: 0.6746, Val Acc: 80.00%\n",
      "Early stopping triggered at epoch 34\n",
      "New best model found with Val Loss: 0.6683 and Test Accuracy: 80.10%\n",
      "\n",
      "== Trial 9/20: {'dropout_p1': 0.5826140369350312, 'dropout_p2': 0.4632366663508594, 'lr': 0.0009979003251972024, 'weight_decay': 0.008402745298277088}\n",
      "Epoch 1/50, Train Loss: 2.1344, Train Acc: 56.08%, Val Loss: 1.2423, Val Acc: 68.90%\n",
      "Epoch 2/50, Train Loss: 1.4750, Train Acc: 62.38%, Val Loss: 1.1875, Val Acc: 70.03%\n",
      "Estimate time per epoch: 16.65 seconds\n",
      "Epoch 3/50, Train Loss: 1.4690, Train Acc: 62.35%, Val Loss: 1.1924, Val Acc: 69.43%\n",
      "Epoch 4/50, Train Loss: 1.4718, Train Acc: 62.32%, Val Loss: 1.1918, Val Acc: 69.49%\n",
      "Epoch 5/50, Train Loss: 1.4668, Train Acc: 62.18%, Val Loss: 1.1726, Val Acc: 69.63%\n",
      "Epoch 6/50, Train Loss: 1.4587, Train Acc: 62.73%, Val Loss: 1.1808, Val Acc: 69.93%\n",
      "Epoch 7/50, Train Loss: 1.4703, Train Acc: 62.23%, Val Loss: 1.2041, Val Acc: 67.77%\n",
      "Epoch 8/50, Train Loss: 1.4659, Train Acc: 62.84%, Val Loss: 1.1481, Val Acc: 70.56%\n",
      "Epoch 9/50, Train Loss: 1.4624, Train Acc: 62.61%, Val Loss: 1.1943, Val Acc: 70.24%\n",
      "Epoch 10/50, Train Loss: 1.4676, Train Acc: 62.66%, Val Loss: 1.1884, Val Acc: 68.93%\n",
      "Epoch 11/50, Train Loss: 1.4548, Train Acc: 62.97%, Val Loss: 1.1712, Val Acc: 69.89%\n",
      "Epoch 12/50, Train Loss: 1.4678, Train Acc: 62.43%, Val Loss: 1.1796, Val Acc: 69.96%\n",
      "Early stopping triggered at epoch 13\n",
      "No improvement. Current Best Val Loss: 0.6683, Test Accuracy: 80.10%\n",
      "\n",
      "== Trial 10/20: {'dropout_p1': 0.5957065709730299, 'dropout_p2': 0.4080797150366654, 'lr': 0.0002324824699249054, 'weight_decay': 0.009820207344886114}\n",
      "Epoch 1/50, Train Loss: 3.5224, Train Acc: 51.59%, Val Loss: 1.2526, Val Acc: 73.09%\n",
      "Epoch 2/50, Train Loss: 1.3030, Train Acc: 69.75%, Val Loss: 1.0565, Val Acc: 75.06%\n",
      "Estimate time per epoch: 17.57 seconds\n",
      "Epoch 3/50, Train Loss: 1.2148, Train Acc: 71.52%, Val Loss: 1.0111, Val Acc: 75.64%\n",
      "Epoch 4/50, Train Loss: 1.1843, Train Acc: 72.29%, Val Loss: 0.9936, Val Acc: 76.07%\n",
      "Epoch 5/50, Train Loss: 1.1658, Train Acc: 72.54%, Val Loss: 0.9903, Val Acc: 76.25%\n",
      "Epoch 6/50, Train Loss: 1.1545, Train Acc: 72.91%, Val Loss: 0.9780, Val Acc: 76.46%\n",
      "Epoch 7/50, Train Loss: 1.1534, Train Acc: 72.84%, Val Loss: 0.9690, Val Acc: 75.90%\n",
      "Epoch 8/50, Train Loss: 1.1399, Train Acc: 72.95%, Val Loss: 0.9695, Val Acc: 76.58%\n",
      "Epoch 9/50, Train Loss: 1.1338, Train Acc: 73.27%, Val Loss: 0.9565, Val Acc: 76.69%\n",
      "Epoch 10/50, Train Loss: 1.1317, Train Acc: 73.31%, Val Loss: 0.9528, Val Acc: 76.36%\n",
      "Epoch 11/50, Train Loss: 1.1293, Train Acc: 73.56%, Val Loss: 0.9552, Val Acc: 76.42%\n",
      "Epoch 12/50, Train Loss: 1.1292, Train Acc: 73.43%, Val Loss: 0.9545, Val Acc: 76.43%\n",
      "Epoch 13/50, Train Loss: 1.1279, Train Acc: 73.20%, Val Loss: 0.9553, Val Acc: 76.48%\n",
      "Epoch 14/50, Train Loss: 1.1234, Train Acc: 73.42%, Val Loss: 0.9504, Val Acc: 76.89%\n",
      "Epoch 15/50, Train Loss: 1.1367, Train Acc: 73.11%, Val Loss: 0.9561, Val Acc: 76.45%\n",
      "Epoch 16/50, Train Loss: 1.1228, Train Acc: 73.64%, Val Loss: 0.9400, Val Acc: 76.97%\n",
      "Epoch 17/50, Train Loss: 1.1214, Train Acc: 73.53%, Val Loss: 0.9443, Val Acc: 77.18%\n",
      "Epoch 18/50, Train Loss: 1.1261, Train Acc: 73.30%, Val Loss: 0.9580, Val Acc: 76.65%\n",
      "Epoch 19/50, Train Loss: 1.1217, Train Acc: 73.38%, Val Loss: 0.9486, Val Acc: 76.27%\n",
      "Epoch 20/50, Train Loss: 1.1195, Train Acc: 73.64%, Val Loss: 0.9401, Val Acc: 76.70%\n",
      "Early stopping triggered at epoch 21\n",
      "No improvement. Current Best Val Loss: 0.6683, Test Accuracy: 80.10%\n",
      "\n",
      "== Trial 11/20: {'dropout_p1': 0.6444543635409097, 'dropout_p2': 0.5486460754013094, 'lr': 0.0008706049995676486, 'weight_decay': 0.007248159535949158}\n",
      "Epoch 1/50, Train Loss: 2.3142, Train Acc: 53.28%, Val Loss: 1.2082, Val Acc: 69.09%\n",
      "Epoch 2/50, Train Loss: 1.4663, Train Acc: 62.25%, Val Loss: 1.1410, Val Acc: 70.73%\n",
      "Estimate time per epoch: 16.25 seconds\n",
      "Epoch 3/50, Train Loss: 1.4519, Train Acc: 62.80%, Val Loss: 1.1140, Val Acc: 71.43%\n",
      "Epoch 4/50, Train Loss: 1.4515, Train Acc: 62.52%, Val Loss: 1.1293, Val Acc: 70.38%\n",
      "Epoch 5/50, Train Loss: 1.4468, Train Acc: 62.54%, Val Loss: 1.1050, Val Acc: 71.01%\n",
      "Epoch 6/50, Train Loss: 1.4526, Train Acc: 62.47%, Val Loss: 1.1356, Val Acc: 70.17%\n",
      "Epoch 7/50, Train Loss: 1.4387, Train Acc: 62.80%, Val Loss: 1.1517, Val Acc: 69.89%\n",
      "Epoch 8/50, Train Loss: 1.4530, Train Acc: 62.34%, Val Loss: 1.1027, Val Acc: 71.45%\n",
      "Epoch 9/50, Train Loss: 1.4424, Train Acc: 62.76%, Val Loss: 1.0979, Val Acc: 71.50%\n",
      "Epoch 10/50, Train Loss: 1.4518, Train Acc: 62.44%, Val Loss: 1.1025, Val Acc: 71.03%\n",
      "Epoch 11/50, Train Loss: 1.4490, Train Acc: 62.35%, Val Loss: 1.1037, Val Acc: 71.23%\n",
      "Epoch 12/50, Train Loss: 1.4563, Train Acc: 62.52%, Val Loss: 1.1166, Val Acc: 70.65%\n",
      "Epoch 13/50, Train Loss: 1.4409, Train Acc: 63.02%, Val Loss: 1.1011, Val Acc: 71.66%\n",
      "Early stopping triggered at epoch 14\n",
      "No improvement. Current Best Val Loss: 0.6683, Test Accuracy: 80.10%\n",
      "\n",
      "== Trial 12/20: {'dropout_p1': 0.6606482773491162, 'dropout_p2': 0.586996657008257, 'lr': 0.00015500001174270617, 'weight_decay': 0.0013964555537586774}\n",
      "Epoch 1/50, Train Loss: 4.6289, Train Acc: 36.62%, Val Loss: 1.7123, Val Acc: 68.83%\n",
      "Epoch 2/50, Train Loss: 1.5041, Train Acc: 62.59%, Val Loss: 1.0038, Val Acc: 74.53%\n",
      "Estimate time per epoch: 15.67 seconds\n",
      "Epoch 3/50, Train Loss: 1.1839, Train Acc: 68.51%, Val Loss: 0.8615, Val Acc: 76.48%\n",
      "Epoch 4/50, Train Loss: 1.0702, Train Acc: 70.62%, Val Loss: 0.8077, Val Acc: 77.03%\n",
      "Epoch 5/50, Train Loss: 1.0036, Train Acc: 71.81%, Val Loss: 0.7808, Val Acc: 77.44%\n",
      "Epoch 6/50, Train Loss: 0.9657, Train Acc: 72.83%, Val Loss: 0.7624, Val Acc: 78.19%\n",
      "Epoch 7/50, Train Loss: 0.9293, Train Acc: 73.94%, Val Loss: 0.7578, Val Acc: 77.57%\n",
      "Epoch 8/50, Train Loss: 0.9070, Train Acc: 74.59%, Val Loss: 0.7419, Val Acc: 78.25%\n",
      "Epoch 9/50, Train Loss: 0.8908, Train Acc: 74.78%, Val Loss: 0.7387, Val Acc: 78.37%\n",
      "Epoch 10/50, Train Loss: 0.8696, Train Acc: 75.56%, Val Loss: 0.7284, Val Acc: 78.57%\n",
      "Epoch 11/50, Train Loss: 0.8572, Train Acc: 75.75%, Val Loss: 0.7268, Val Acc: 78.67%\n",
      "Epoch 12/50, Train Loss: 0.8409, Train Acc: 76.30%, Val Loss: 0.7189, Val Acc: 78.76%\n",
      "Epoch 13/50, Train Loss: 0.8309, Train Acc: 76.36%, Val Loss: 0.7204, Val Acc: 78.70%\n",
      "Epoch 14/50, Train Loss: 0.8185, Train Acc: 76.85%, Val Loss: 0.7083, Val Acc: 78.92%\n",
      "Epoch 15/50, Train Loss: 0.8143, Train Acc: 76.82%, Val Loss: 0.7140, Val Acc: 78.89%\n",
      "Epoch 16/50, Train Loss: 0.7985, Train Acc: 76.90%, Val Loss: 0.7077, Val Acc: 79.10%\n",
      "Epoch 17/50, Train Loss: 0.7972, Train Acc: 77.34%, Val Loss: 0.7048, Val Acc: 78.86%\n",
      "Epoch 18/50, Train Loss: 0.7958, Train Acc: 77.39%, Val Loss: 0.7069, Val Acc: 78.94%\n",
      "Epoch 19/50, Train Loss: 0.7815, Train Acc: 77.71%, Val Loss: 0.7042, Val Acc: 79.01%\n",
      "Epoch 20/50, Train Loss: 0.7776, Train Acc: 77.62%, Val Loss: 0.6967, Val Acc: 79.28%\n",
      "Epoch 21/50, Train Loss: 0.7637, Train Acc: 78.12%, Val Loss: 0.6982, Val Acc: 79.24%\n",
      "Epoch 22/50, Train Loss: 0.7646, Train Acc: 78.11%, Val Loss: 0.6977, Val Acc: 79.13%\n",
      "Epoch 23/50, Train Loss: 0.7656, Train Acc: 78.20%, Val Loss: 0.7007, Val Acc: 79.19%\n",
      "Epoch 24/50, Train Loss: 0.7572, Train Acc: 78.34%, Val Loss: 0.6965, Val Acc: 79.59%\n",
      "Epoch 25/50, Train Loss: 0.7416, Train Acc: 78.89%, Val Loss: 0.6953, Val Acc: 79.27%\n",
      "Epoch 26/50, Train Loss: 0.7418, Train Acc: 78.68%, Val Loss: 0.6938, Val Acc: 79.54%\n",
      "Epoch 27/50, Train Loss: 0.7392, Train Acc: 78.66%, Val Loss: 0.6991, Val Acc: 79.29%\n",
      "Epoch 28/50, Train Loss: 0.7364, Train Acc: 78.66%, Val Loss: 0.6989, Val Acc: 79.45%\n",
      "Epoch 29/50, Train Loss: 0.7288, Train Acc: 79.08%, Val Loss: 0.6920, Val Acc: 79.30%\n",
      "Epoch 30/50, Train Loss: 0.7280, Train Acc: 79.14%, Val Loss: 0.6916, Val Acc: 79.30%\n",
      "Epoch 31/50, Train Loss: 0.7212, Train Acc: 79.40%, Val Loss: 0.6953, Val Acc: 79.47%\n",
      "Epoch 32/50, Train Loss: 0.7242, Train Acc: 79.18%, Val Loss: 0.6856, Val Acc: 79.79%\n",
      "Epoch 33/50, Train Loss: 0.7187, Train Acc: 79.10%, Val Loss: 0.6935, Val Acc: 79.46%\n",
      "Epoch 34/50, Train Loss: 0.7081, Train Acc: 79.78%, Val Loss: 0.6848, Val Acc: 79.62%\n",
      "Epoch 35/50, Train Loss: 0.7105, Train Acc: 79.56%, Val Loss: 0.6896, Val Acc: 79.45%\n",
      "Epoch 36/50, Train Loss: 0.7076, Train Acc: 79.67%, Val Loss: 0.6899, Val Acc: 79.71%\n",
      "Epoch 37/50, Train Loss: 0.7043, Train Acc: 79.72%, Val Loss: 0.6877, Val Acc: 79.64%\n",
      "Epoch 38/50, Train Loss: 0.6965, Train Acc: 79.97%, Val Loss: 0.6840, Val Acc: 79.82%\n",
      "Epoch 39/50, Train Loss: 0.6960, Train Acc: 80.02%, Val Loss: 0.6848, Val Acc: 79.73%\n",
      "Epoch 40/50, Train Loss: 0.6937, Train Acc: 79.98%, Val Loss: 0.6854, Val Acc: 79.66%\n",
      "Epoch 41/50, Train Loss: 0.6845, Train Acc: 80.51%, Val Loss: 0.6920, Val Acc: 79.58%\n",
      "Epoch 42/50, Train Loss: 0.6874, Train Acc: 80.08%, Val Loss: 0.6865, Val Acc: 79.54%\n",
      "Early stopping triggered at epoch 43\n",
      "No improvement. Current Best Val Loss: 0.6683, Test Accuracy: 80.10%\n",
      "\n",
      "== Trial 13/20: {'dropout_p1': 0.6378487328633367, 'dropout_p2': 0.5786937852382005, 'lr': 0.0006904446634608864, 'weight_decay': 0.004088683858873309}\n",
      "Epoch 1/50, Train Loss: 2.3807, Train Acc: 53.70%, Val Loss: 1.0092, Val Acc: 73.75%\n",
      "Epoch 2/50, Train Loss: 1.2951, Train Acc: 65.40%, Val Loss: 0.9673, Val Acc: 73.85%\n",
      "Estimate time per epoch: 15.64 seconds\n",
      "Epoch 3/50, Train Loss: 1.2525, Train Acc: 66.41%, Val Loss: 0.9688, Val Acc: 73.57%\n",
      "Epoch 4/50, Train Loss: 1.2416, Train Acc: 66.74%, Val Loss: 0.9455, Val Acc: 74.12%\n",
      "Epoch 5/50, Train Loss: 1.2410, Train Acc: 66.69%, Val Loss: 0.9433, Val Acc: 73.97%\n",
      "Epoch 6/50, Train Loss: 1.2353, Train Acc: 66.88%, Val Loss: 0.9509, Val Acc: 73.86%\n",
      "Epoch 7/50, Train Loss: 1.2278, Train Acc: 67.01%, Val Loss: 0.9303, Val Acc: 74.14%\n",
      "Epoch 8/50, Train Loss: 1.2292, Train Acc: 67.02%, Val Loss: 0.9390, Val Acc: 73.55%\n",
      "Epoch 9/50, Train Loss: 1.2371, Train Acc: 66.70%, Val Loss: 0.9396, Val Acc: 73.52%\n",
      "Epoch 10/50, Train Loss: 1.2308, Train Acc: 67.07%, Val Loss: 0.9365, Val Acc: 74.04%\n",
      "Epoch 11/50, Train Loss: 1.2320, Train Acc: 66.90%, Val Loss: 0.9262, Val Acc: 74.08%\n",
      "Epoch 12/50, Train Loss: 1.2264, Train Acc: 66.97%, Val Loss: 0.9321, Val Acc: 74.34%\n",
      "Epoch 13/50, Train Loss: 1.2274, Train Acc: 67.19%, Val Loss: 0.9528, Val Acc: 73.59%\n",
      "Epoch 14/50, Train Loss: 1.2282, Train Acc: 66.81%, Val Loss: 0.9319, Val Acc: 73.88%\n",
      "Epoch 15/50, Train Loss: 1.2319, Train Acc: 67.01%, Val Loss: 0.9296, Val Acc: 74.23%\n",
      "Epoch 16/50, Train Loss: 1.2284, Train Acc: 66.87%, Val Loss: 0.9234, Val Acc: 74.41%\n",
      "Epoch 17/50, Train Loss: 1.2274, Train Acc: 67.16%, Val Loss: 0.9380, Val Acc: 73.72%\n",
      "Epoch 18/50, Train Loss: 1.2295, Train Acc: 67.14%, Val Loss: 0.9226, Val Acc: 74.48%\n",
      "Epoch 19/50, Train Loss: 1.2281, Train Acc: 67.08%, Val Loss: 0.9237, Val Acc: 74.20%\n",
      "Epoch 20/50, Train Loss: 1.2250, Train Acc: 67.22%, Val Loss: 0.9249, Val Acc: 74.69%\n",
      "Epoch 21/50, Train Loss: 1.2264, Train Acc: 66.94%, Val Loss: 0.9216, Val Acc: 74.48%\n",
      "Epoch 22/50, Train Loss: 1.2242, Train Acc: 67.32%, Val Loss: 0.9376, Val Acc: 73.65%\n",
      "Epoch 23/50, Train Loss: 1.2289, Train Acc: 66.96%, Val Loss: 0.9396, Val Acc: 73.51%\n",
      "Epoch 24/50, Train Loss: 1.2250, Train Acc: 67.31%, Val Loss: 0.9322, Val Acc: 73.86%\n",
      "Epoch 25/50, Train Loss: 1.2291, Train Acc: 67.04%, Val Loss: 0.9256, Val Acc: 74.22%\n",
      "Early stopping triggered at epoch 26\n",
      "No improvement. Current Best Val Loss: 0.6683, Test Accuracy: 80.10%\n",
      "\n",
      "== Trial 14/20: {'dropout_p1': 0.614543183776441, 'dropout_p2': 0.5795402374601393, 'lr': 0.00031489775123550714, 'weight_decay': 0.006855030253108802}\n",
      "Epoch 1/50, Train Loss: 3.3392, Train Acc: 48.83%, Val Loss: 1.1639, Val Acc: 72.50%\n",
      "Epoch 2/50, Train Loss: 1.3249, Train Acc: 67.47%, Val Loss: 1.0143, Val Acc: 74.30%\n",
      "Estimate time per epoch: 16.85 seconds\n",
      "Epoch 3/50, Train Loss: 1.2324, Train Acc: 69.08%, Val Loss: 0.9733, Val Acc: 75.06%\n",
      "Epoch 4/50, Train Loss: 1.2024, Train Acc: 70.14%, Val Loss: 0.9658, Val Acc: 75.19%\n",
      "Epoch 5/50, Train Loss: 1.1858, Train Acc: 70.00%, Val Loss: 0.9433, Val Acc: 75.28%\n",
      "Epoch 6/50, Train Loss: 1.1702, Train Acc: 70.69%, Val Loss: 0.9272, Val Acc: 75.48%\n",
      "Epoch 7/50, Train Loss: 1.1675, Train Acc: 70.63%, Val Loss: 0.9232, Val Acc: 75.94%\n",
      "Epoch 8/50, Train Loss: 1.1512, Train Acc: 71.31%, Val Loss: 0.9174, Val Acc: 76.22%\n",
      "Epoch 9/50, Train Loss: 1.1529, Train Acc: 71.11%, Val Loss: 0.9225, Val Acc: 75.99%\n",
      "Epoch 10/50, Train Loss: 1.1460, Train Acc: 71.24%, Val Loss: 0.9108, Val Acc: 76.33%\n",
      "Epoch 11/50, Train Loss: 1.1448, Train Acc: 71.27%, Val Loss: 0.9093, Val Acc: 76.04%\n",
      "Epoch 12/50, Train Loss: 1.1370, Train Acc: 71.61%, Val Loss: 0.9080, Val Acc: 75.96%\n",
      "Epoch 13/50, Train Loss: 1.1414, Train Acc: 71.61%, Val Loss: 0.9065, Val Acc: 76.33%\n",
      "Epoch 14/50, Train Loss: 1.1387, Train Acc: 71.54%, Val Loss: 0.8952, Val Acc: 76.42%\n",
      "Epoch 15/50, Train Loss: 1.1402, Train Acc: 71.39%, Val Loss: 0.8965, Val Acc: 77.11%\n",
      "Epoch 16/50, Train Loss: 1.1350, Train Acc: 71.93%, Val Loss: 0.8963, Val Acc: 75.98%\n",
      "Epoch 17/50, Train Loss: 1.1374, Train Acc: 71.51%, Val Loss: 0.8845, Val Acc: 76.78%\n",
      "Epoch 18/50, Train Loss: 1.1376, Train Acc: 71.66%, Val Loss: 0.9016, Val Acc: 76.27%\n",
      "Epoch 19/50, Train Loss: 1.1375, Train Acc: 71.27%, Val Loss: 0.8983, Val Acc: 76.69%\n",
      "Epoch 20/50, Train Loss: 1.1328, Train Acc: 71.86%, Val Loss: 0.9077, Val Acc: 76.21%\n",
      "Epoch 21/50, Train Loss: 1.1342, Train Acc: 71.91%, Val Loss: 0.9117, Val Acc: 75.89%\n",
      "Early stopping triggered at epoch 22\n",
      "No improvement. Current Best Val Loss: 0.6683, Test Accuracy: 80.10%\n",
      "\n",
      "== Trial 15/20: {'dropout_p1': 0.5796012181629621, 'dropout_p2': 0.42212144945324714, 'lr': 0.0003316945494750594, 'weight_decay': 0.004974606629868139}\n",
      "Epoch 1/50, Train Loss: 2.7751, Train Acc: 55.75%, Val Loss: 1.0242, Val Acc: 74.33%\n",
      "Epoch 2/50, Train Loss: 1.1352, Train Acc: 70.68%, Val Loss: 0.9219, Val Acc: 75.75%\n",
      "Estimate time per epoch: 18.29 seconds\n",
      "Epoch 3/50, Train Loss: 1.0675, Train Acc: 72.33%, Val Loss: 0.9033, Val Acc: 75.85%\n",
      "Epoch 4/50, Train Loss: 1.0391, Train Acc: 72.92%, Val Loss: 0.8712, Val Acc: 76.50%\n",
      "Epoch 5/50, Train Loss: 1.0221, Train Acc: 73.01%, Val Loss: 0.8782, Val Acc: 76.02%\n",
      "Epoch 6/50, Train Loss: 1.0198, Train Acc: 73.36%, Val Loss: 0.8619, Val Acc: 76.61%\n",
      "Epoch 7/50, Train Loss: 1.0087, Train Acc: 73.60%, Val Loss: 0.8558, Val Acc: 76.45%\n",
      "Epoch 8/50, Train Loss: 1.0025, Train Acc: 73.50%, Val Loss: 0.8470, Val Acc: 76.70%\n",
      "Epoch 9/50, Train Loss: 0.9985, Train Acc: 73.63%, Val Loss: 0.8581, Val Acc: 76.40%\n",
      "Epoch 10/50, Train Loss: 0.9915, Train Acc: 73.92%, Val Loss: 0.8542, Val Acc: 76.60%\n",
      "Epoch 11/50, Train Loss: 0.9895, Train Acc: 73.98%, Val Loss: 0.8414, Val Acc: 77.19%\n",
      "Epoch 12/50, Train Loss: 0.9930, Train Acc: 73.94%, Val Loss: 0.8522, Val Acc: 76.57%\n",
      "Epoch 13/50, Train Loss: 0.9922, Train Acc: 73.78%, Val Loss: 0.8541, Val Acc: 76.64%\n",
      "Epoch 14/50, Train Loss: 1.0001, Train Acc: 73.77%, Val Loss: 0.8556, Val Acc: 76.49%\n",
      "Epoch 15/50, Train Loss: 0.9867, Train Acc: 74.03%, Val Loss: 0.8352, Val Acc: 77.00%\n",
      "Epoch 16/50, Train Loss: 0.9904, Train Acc: 73.75%, Val Loss: 0.8376, Val Acc: 77.41%\n",
      "Epoch 17/50, Train Loss: 0.9923, Train Acc: 73.77%, Val Loss: 0.8423, Val Acc: 76.89%\n",
      "Epoch 18/50, Train Loss: 0.9829, Train Acc: 74.38%, Val Loss: 0.8365, Val Acc: 76.74%\n",
      "Epoch 19/50, Train Loss: 0.9831, Train Acc: 74.17%, Val Loss: 0.8499, Val Acc: 76.47%\n",
      "Early stopping triggered at epoch 20\n",
      "No improvement. Current Best Val Loss: 0.6683, Test Accuracy: 80.10%\n",
      "\n",
      "== Trial 16/20: {'dropout_p1': 0.561374440867849, 'dropout_p2': 0.42955250817471735, 'lr': 0.0008403073292884604, 'weight_decay': 0.0018342853188128324}\n",
      "Epoch 1/50, Train Loss: 1.8714, Train Acc: 60.06%, Val Loss: 0.9031, Val Acc: 74.37%\n",
      "Epoch 2/50, Train Loss: 1.1000, Train Acc: 69.27%, Val Loss: 0.8729, Val Acc: 75.38%\n",
      "Estimate time per epoch: 18.50 seconds\n",
      "Epoch 3/50, Train Loss: 1.0583, Train Acc: 70.28%, Val Loss: 0.8651, Val Acc: 74.72%\n",
      "Epoch 4/50, Train Loss: 1.0496, Train Acc: 70.25%, Val Loss: 0.8771, Val Acc: 74.44%\n",
      "Epoch 5/50, Train Loss: 1.0385, Train Acc: 70.53%, Val Loss: 0.8789, Val Acc: 74.53%\n",
      "Epoch 6/50, Train Loss: 1.0336, Train Acc: 70.78%, Val Loss: 0.8687, Val Acc: 74.80%\n",
      "Epoch 7/50, Train Loss: 1.0348, Train Acc: 70.95%, Val Loss: 0.8646, Val Acc: 74.73%\n",
      "Epoch 8/50, Train Loss: 1.0316, Train Acc: 70.84%, Val Loss: 0.8503, Val Acc: 75.50%\n",
      "Epoch 9/50, Train Loss: 1.0334, Train Acc: 70.46%, Val Loss: 0.8428, Val Acc: 75.62%\n",
      "Epoch 10/50, Train Loss: 1.0355, Train Acc: 70.58%, Val Loss: 0.8596, Val Acc: 75.13%\n",
      "Epoch 11/50, Train Loss: 1.0375, Train Acc: 70.54%, Val Loss: 0.8433, Val Acc: 75.61%\n",
      "Epoch 12/50, Train Loss: 1.0292, Train Acc: 70.92%, Val Loss: 0.8491, Val Acc: 75.42%\n",
      "Epoch 13/50, Train Loss: 1.0374, Train Acc: 70.67%, Val Loss: 0.8517, Val Acc: 75.44%\n",
      "Early stopping triggered at epoch 14\n",
      "No improvement. Current Best Val Loss: 0.6683, Test Accuracy: 80.10%\n",
      "\n",
      "== Trial 17/20: {'dropout_p1': 0.5058887501321823, 'dropout_p2': 0.43805567144593616, 'lr': 0.0003001190019361799, 'weight_decay': 0.008536388475801921}\n",
      "Epoch 1/50, Train Loss: 2.9483, Train Acc: 56.02%, Val Loss: 1.1132, Val Acc: 73.71%\n",
      "Epoch 2/50, Train Loss: 1.2150, Train Acc: 70.85%, Val Loss: 0.9977, Val Acc: 75.41%\n",
      "Estimate time per epoch: 17.78 seconds\n",
      "Epoch 3/50, Train Loss: 1.1515, Train Acc: 72.31%, Val Loss: 0.9796, Val Acc: 75.59%\n",
      "Epoch 4/50, Train Loss: 1.1318, Train Acc: 72.51%, Val Loss: 0.9595, Val Acc: 76.02%\n",
      "Epoch 5/50, Train Loss: 1.1185, Train Acc: 72.80%, Val Loss: 0.9434, Val Acc: 76.28%\n",
      "Epoch 6/50, Train Loss: 1.1029, Train Acc: 73.07%, Val Loss: 0.9480, Val Acc: 75.99%\n",
      "Epoch 7/50, Train Loss: 1.1009, Train Acc: 73.15%, Val Loss: 0.9494, Val Acc: 75.92%\n",
      "Epoch 8/50, Train Loss: 1.0924, Train Acc: 73.38%, Val Loss: 0.9445, Val Acc: 76.24%\n",
      "Epoch 9/50, Train Loss: 1.0964, Train Acc: 73.34%, Val Loss: 0.9491, Val Acc: 75.64%\n",
      "Epoch 10/50, Train Loss: 1.0954, Train Acc: 73.36%, Val Loss: 0.9269, Val Acc: 76.13%\n",
      "Epoch 11/50, Train Loss: 1.0921, Train Acc: 73.50%, Val Loss: 0.9371, Val Acc: 76.24%\n",
      "Epoch 12/50, Train Loss: 1.0845, Train Acc: 73.49%, Val Loss: 0.9228, Val Acc: 76.49%\n",
      "Epoch 13/50, Train Loss: 1.0903, Train Acc: 73.47%, Val Loss: 0.9316, Val Acc: 76.48%\n",
      "Epoch 14/50, Train Loss: 1.0863, Train Acc: 73.80%, Val Loss: 0.9285, Val Acc: 76.31%\n",
      "Epoch 15/50, Train Loss: 1.0886, Train Acc: 73.28%, Val Loss: 0.9231, Val Acc: 76.65%\n",
      "Epoch 16/50, Train Loss: 1.0869, Train Acc: 73.72%, Val Loss: 0.9238, Val Acc: 76.12%\n",
      "Early stopping triggered at epoch 17\n",
      "No improvement. Current Best Val Loss: 0.6683, Test Accuracy: 80.10%\n",
      "\n",
      "== Trial 18/20: {'dropout_p1': 0.6462521761152951, 'dropout_p2': 0.5709389258976612, 'lr': 0.000775864730126564, 'weight_decay': 0.008089561846523145}\n",
      "Epoch 1/50, Train Loss: 2.4377, Train Acc: 53.45%, Val Loss: 1.2162, Val Acc: 69.58%\n",
      "Epoch 2/50, Train Loss: 1.4895, Train Acc: 62.43%, Val Loss: 1.1546, Val Acc: 70.51%\n",
      "Estimate time per epoch: 16.32 seconds\n",
      "Epoch 3/50, Train Loss: 1.4743, Train Acc: 62.44%, Val Loss: 1.1327, Val Acc: 70.72%\n",
      "Epoch 4/50, Train Loss: 1.4674, Train Acc: 62.70%, Val Loss: 1.1282, Val Acc: 71.92%\n",
      "Epoch 5/50, Train Loss: 1.4613, Train Acc: 63.05%, Val Loss: 1.1216, Val Acc: 71.29%\n",
      "Epoch 6/50, Train Loss: 1.4555, Train Acc: 62.84%, Val Loss: 1.1195, Val Acc: 71.16%\n",
      "Epoch 7/50, Train Loss: 1.4596, Train Acc: 62.90%, Val Loss: 1.1154, Val Acc: 70.97%\n",
      "Epoch 8/50, Train Loss: 1.4573, Train Acc: 62.96%, Val Loss: 1.1138, Val Acc: 71.20%\n",
      "Epoch 9/50, Train Loss: 1.4573, Train Acc: 63.12%, Val Loss: 1.1222, Val Acc: 71.73%\n",
      "Epoch 10/50, Train Loss: 1.4592, Train Acc: 63.03%, Val Loss: 1.1274, Val Acc: 71.03%\n",
      "Epoch 11/50, Train Loss: 1.4531, Train Acc: 62.96%, Val Loss: 1.1326, Val Acc: 71.60%\n",
      "Epoch 12/50, Train Loss: 1.4477, Train Acc: 63.34%, Val Loss: 1.1218, Val Acc: 71.65%\n",
      "Early stopping triggered at epoch 13\n",
      "No improvement. Current Best Val Loss: 0.6683, Test Accuracy: 80.10%\n",
      "\n",
      "== Trial 19/20: {'dropout_p1': 0.5097330482843586, 'dropout_p2': 0.4210302567915149, 'lr': 0.0006839853490474565, 'weight_decay': 0.00843676054704429}\n",
      "Epoch 1/50, Train Loss: 2.1756, Train Acc: 59.11%, Val Loss: 1.1419, Val Acc: 72.14%\n",
      "Epoch 2/50, Train Loss: 1.3244, Train Acc: 66.78%, Val Loss: 1.1199, Val Acc: 71.97%\n",
      "Estimate time per epoch: 15.56 seconds\n",
      "Epoch 3/50, Train Loss: 1.3010, Train Acc: 67.33%, Val Loss: 1.1105, Val Acc: 71.64%\n",
      "Epoch 4/50, Train Loss: 1.3019, Train Acc: 67.25%, Val Loss: 1.0740, Val Acc: 72.31%\n",
      "Epoch 5/50, Train Loss: 1.2992, Train Acc: 67.27%, Val Loss: 1.0820, Val Acc: 72.66%\n",
      "Epoch 6/50, Train Loss: 1.2974, Train Acc: 67.27%, Val Loss: 1.0868, Val Acc: 72.35%\n",
      "Epoch 7/50, Train Loss: 1.2902, Train Acc: 67.37%, Val Loss: 1.0728, Val Acc: 72.16%\n",
      "Epoch 8/50, Train Loss: 1.3006, Train Acc: 67.23%, Val Loss: 1.0703, Val Acc: 72.58%\n",
      "Epoch 9/50, Train Loss: 1.2906, Train Acc: 67.41%, Val Loss: 1.0393, Val Acc: 73.85%\n",
      "Epoch 10/50, Train Loss: 1.2943, Train Acc: 67.55%, Val Loss: 1.0624, Val Acc: 72.87%\n",
      "Epoch 11/50, Train Loss: 1.2898, Train Acc: 67.56%, Val Loss: 1.0521, Val Acc: 73.11%\n",
      "Epoch 12/50, Train Loss: 1.2963, Train Acc: 67.37%, Val Loss: 1.0740, Val Acc: 72.29%\n",
      "Epoch 13/50, Train Loss: 1.2900, Train Acc: 67.66%, Val Loss: 1.0491, Val Acc: 73.02%\n",
      "Early stopping triggered at epoch 14\n",
      "No improvement. Current Best Val Loss: 0.6683, Test Accuracy: 80.10%\n",
      "\n",
      "== Trial 20/20: {'dropout_p1': 0.5073321873134163, 'dropout_p2': 0.4712807588660241, 'lr': 0.0005651464581152874, 'weight_decay': 0.00485064104213019}\n",
      "Epoch 1/50, Train Loss: 2.2150, Train Acc: 59.49%, Val Loss: 0.9991, Val Acc: 72.99%\n",
      "Epoch 2/50, Train Loss: 1.1598, Train Acc: 69.58%, Val Loss: 0.9371, Val Acc: 74.79%\n",
      "Estimate time per epoch: 14.21 seconds\n",
      "Epoch 3/50, Train Loss: 1.1182, Train Acc: 70.43%, Val Loss: 0.9241, Val Acc: 74.55%\n",
      "Epoch 4/50, Train Loss: 1.1093, Train Acc: 70.65%, Val Loss: 0.9263, Val Acc: 74.31%\n",
      "Epoch 5/50, Train Loss: 1.1012, Train Acc: 70.62%, Val Loss: 0.9132, Val Acc: 75.55%\n",
      "Epoch 6/50, Train Loss: 1.0988, Train Acc: 70.75%, Val Loss: 0.9201, Val Acc: 74.51%\n",
      "Epoch 7/50, Train Loss: 1.0936, Train Acc: 70.86%, Val Loss: 0.8995, Val Acc: 74.96%\n",
      "Epoch 8/50, Train Loss: 1.0997, Train Acc: 70.86%, Val Loss: 0.9015, Val Acc: 74.79%\n",
      "Epoch 9/50, Train Loss: 1.0942, Train Acc: 71.14%, Val Loss: 0.9029, Val Acc: 75.29%\n",
      "Epoch 10/50, Train Loss: 1.1002, Train Acc: 70.81%, Val Loss: 0.9122, Val Acc: 75.24%\n",
      "Epoch 11/50, Train Loss: 1.0935, Train Acc: 71.11%, Val Loss: 0.9014, Val Acc: 75.49%\n",
      "Epoch 12/50, Train Loss: 1.0955, Train Acc: 70.80%, Val Loss: 0.8970, Val Acc: 75.56%\n",
      "Epoch 13/50, Train Loss: 1.0877, Train Acc: 71.25%, Val Loss: 0.9084, Val Acc: 75.50%\n",
      "Epoch 14/50, Train Loss: 1.0893, Train Acc: 71.21%, Val Loss: 0.9241, Val Acc: 74.49%\n",
      "Epoch 15/50, Train Loss: 1.0959, Train Acc: 71.10%, Val Loss: 0.8996, Val Acc: 75.05%\n",
      "Epoch 16/50, Train Loss: 1.0861, Train Acc: 71.21%, Val Loss: 0.9071, Val Acc: 74.98%\n",
      "Epoch 17/50, Train Loss: 1.0933, Train Acc: 71.00%, Val Loss: 0.8933, Val Acc: 75.68%\n",
      "Epoch 18/50, Train Loss: 1.0849, Train Acc: 71.22%, Val Loss: 0.9133, Val Acc: 74.92%\n",
      "Epoch 19/50, Train Loss: 1.0861, Train Acc: 71.34%, Val Loss: 0.9005, Val Acc: 75.65%\n",
      "Epoch 20/50, Train Loss: 1.0920, Train Acc: 71.12%, Val Loss: 0.8994, Val Acc: 75.36%\n",
      "Epoch 21/50, Train Loss: 1.0849, Train Acc: 71.51%, Val Loss: 0.8922, Val Acc: 75.70%\n",
      "Epoch 22/50, Train Loss: 1.0869, Train Acc: 71.01%, Val Loss: 0.9092, Val Acc: 75.19%\n",
      "Epoch 23/50, Train Loss: 1.0868, Train Acc: 71.36%, Val Loss: 0.8975, Val Acc: 75.34%\n",
      "Epoch 24/50, Train Loss: 1.0912, Train Acc: 71.17%, Val Loss: 0.8958, Val Acc: 75.46%\n",
      "Epoch 25/50, Train Loss: 1.0854, Train Acc: 71.34%, Val Loss: 0.9099, Val Acc: 75.06%\n",
      "Early stopping triggered at epoch 26\n",
      "No improvement. Current Best Val Loss: 0.6683, Test Accuracy: 80.10%\n",
      "\n",
      "=== Random Hyperparameter Search Completed ===\n",
      "Best Parameters Found:\n",
      "{'dropout_p1': 0.5253554572783057, 'dropout_p2': 0.5851059705301832, 'lr': 0.00011730797198485153, 'weight_decay': 0.0013219888016557314}\n",
      "Best Validation Loss: 0.6683\n",
      "Test Accuracy with Best Params: 80.10%\n"
     ]
    }
   ],
   "source": [
    "# Define random search ranges around the previously best parameters.\n",
    "# These ranges are just an example; adjust as needed.\n",
    "dropout_p1_min, dropout_p1_max = 0.5, 0.7   \n",
    "dropout_p2_min, dropout_p2_max = 0.4, 0.6  \n",
    "lr_min, lr_max = 0.001, 0.00005            \n",
    "weight_decay_min, weight_decay_max = 0.00005, 0.01\n",
    "\n",
    "# Number of random trials\n",
    "n_trials = 20\n",
    "\n",
    "best_params = None\n",
    "best_val_loss = float('inf')\n",
    "best_test_acc = 0.0\n",
    "best_model = None\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "num_classes = len(set(y_train))\n",
    "\n",
    "for i in range(n_trials):\n",
    "    # Randomly sample hyperparameters from the specified ranges\n",
    "    chosen_params = {\n",
    "        'dropout_p1': random.uniform(dropout_p1_min, dropout_p1_max),\n",
    "        'dropout_p2': random.uniform(dropout_p2_min, dropout_p2_max),\n",
    "        'lr': random.uniform(lr_min, lr_max),\n",
    "        'weight_decay': random.uniform(weight_decay_min, weight_decay_max)\n",
    "    }\n",
    "\n",
    "    print(f\"=== Trial {i+1}/{n_trials}: {chosen_params} ===\")\n",
    "\n",
    "    # Train and evaluate the model with the chosen hyperparameters\n",
    "    results = train_and_evaluate(\n",
    "        input_size=input_size,\n",
    "        num_classes=num_classes,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        dropout_p1=chosen_params['dropout_p1'],\n",
    "        dropout_p2=chosen_params['dropout_p2'],\n",
    "        lr=chosen_params['lr'],\n",
    "        weight_decay=chosen_params['weight_decay'],\n",
    "        num_epochs=50,\n",
    "        patience=5,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Check for improvement\n",
    "    if results['val_loss'] < best_val_loss:\n",
    "        best_val_loss = results['val_loss']\n",
    "        best_test_acc = results['test_accuracy']\n",
    "        best_params = chosen_params\n",
    "        best_model = results['model']\n",
    "        print(f\"New best model found with Val Loss: {best_val_loss:.4f} and Test Accuracy: {best_test_acc*100:.2f}%\\n\")\n",
    "    else:\n",
    "        print(f\"No improvement. Current Best Val Loss: {best_val_loss:.4f}, Test Accuracy: {best_test_acc*100:.2f}%\\n\")\n",
    "\n",
    "# After random search\n",
    "print(\"=== Random Hyperparameter Search Completed ===\")\n",
    "print(\"Best Parameters Found:\")\n",
    "print(best_params)\n",
    "print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
    "print(f\"Test Accuracy with Best Params: {best_test_acc*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
